{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell is used to import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "test_data = pd.read_csv('../data/sample_submission.csv')\n",
    "bookings_data = pd.read_csv('../data/bookings_data.csv')\n",
    "bookings = pd.read_csv('../data/bookings.csv')\n",
    "hotel_data = pd.read_csv('../data/hotels_data.csv')\n",
    "customer_data = pd.read_csv('../data/customer_data.csv')\n",
    "payments_data = pd.read_csv('../data/payments_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the payment type to a categorical variable and encoding using sklearnâ€™s LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert payment type to numeric using sk preprocessing label encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(payments_data['payment_type'])\n",
    "payments_data['payment_type'] = le.transform(payments_data['payment_type'])\n",
    "\n",
    "payments_data['payment_type'] = payments_data['payment_type'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating unique values from repeat values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only entries with payment_sequential as 1\n",
    "payments_data_unique = payments_data[payments_data['payment_sequential'] == 1]\n",
    "payments_data_repeat = payments_data[payments_data['payment_sequential'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the repeat values based on payment_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort payments_data_repeat by payment_sequential\n",
    "payments_data_repeat = payments_data_repeat.sort_values(by=['payment_sequential'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the repeated data by adding up the payment_value, payment_installments and payment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making payment data unique for each booking_id by adding the payments made by other methods to primary payment method\n",
    "columns = ['payment_value', 'payment_installments', 'payment_type']\n",
    "\n",
    "for payment_data_repeat in payments_data_repeat.itertuples():\n",
    "    booking_id = payment_data_repeat.booking_id\n",
    "    payment_data_unique = payments_data_unique[payments_data_unique['booking_id'] == booking_id]\n",
    "    for column in columns:\n",
    "        new_value = payment_data_unique[column] + payment_data_repeat.__getattribute__(column)\n",
    "        payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, column] = new_value\n",
    "    payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, 'payment_sequential'] = payment_data_repeat.payment_sequential\n",
    "\n",
    "payments_data_unique['payment_type'] = payments_data_unique['payment_type'] / payments_data_unique['payment_sequential']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the hotel data with the booking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data_new = bookings_data.merge(hotel_data, on='hotel_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the expiry date to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the date format to datetime\n",
    "bookings_data_new['booking_expiry_date'] = pd.to_datetime(bookings_data_new['booking_expiry_date'])\n",
    "\n",
    "# change to seconds\n",
    "bookings_data_new['booking_expiry_date'] = bookings_data_new['booking_expiry_date'].astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the repeated data in bookings_data into unique and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split bookings_data into unique and repeat bookings\n",
    "bookings_data_unique = bookings_data_new[bookings_data_new['booking_sequence_id'] == 1]\n",
    "bookings_data_repeat = bookings_data_new[bookings_data_new['booking_sequence_id'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the repeat data based on booking_sequence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort bookings_data_repeat by booking_sequence_id\n",
    "bookings_data_repeat = bookings_data_repeat.sort_values(by=['booking_sequence_id'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging bookings_data for each booking_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging bookings_data for each booking_id\n",
    "columns = ['price', 'agent_fees', 'hotel_category', 'hotel_name_length', 'hotel_description_length', 'hotel_photos_qty', 'booking_expiry_date']\n",
    "\n",
    "for booking_data_repeat in bookings_data_repeat.itertuples():\n",
    "    bookings_id = booking_data_repeat.booking_id\n",
    "    booking_data_unique = bookings_data_unique[bookings_data_unique['booking_id'] == bookings_id]\n",
    "    for column in columns:\n",
    "        new_value = booking_data_unique[column] + booking_data_repeat.__getattribute__(column)\n",
    "        bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, column] = new_value\n",
    "    bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, 'booking_sequence_id'] = booking_data_repeat.booking_sequence_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking average for a few columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make entries in bookings_data_unique by taking average of the values based in booking_sequence_id\n",
    "columns = ['hotel_category', 'hotel_name_length', 'hotel_description_length', 'hotel_photos_qty', 'booking_expiry_date']\n",
    "\n",
    "for column in columns:\n",
    "    bookings_data_unique[column] = bookings_data_unique[column] / bookings_data_unique['booking_sequence_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the booking data from both sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings and bookings_data as bookings_df\n",
    "bookings_df = pd.merge(bookings, bookings_data_unique, on='booking_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging customer and payment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings_df and customer_data as bookings_customer_df\n",
    "bookings_customer_df = pd.merge(bookings_df, customer_data, on='customer_id', how='left')\n",
    "\n",
    "# merge bookings_hotel_df and payments_data as bookings_payment_df\n",
    "bookings_payment_df = pd.merge(bookings_customer_df, payments_data_unique, on='booking_id', how='left')\n",
    "\n",
    "bookings_payment_df.drop(['customer_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making numerical encodings for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['seller_agent_id', 'booking_status', 'country', 'customer_unique_id', 'hotel_id']\n",
    "\n",
    "for column in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(bookings_payment_df[column])\n",
    "    bookings_payment_df[column] = le.transform(bookings_payment_df[column])\n",
    "    if column == 'booking_status' or column == 'country':\n",
    "        bookings_payment_df[column] = bookings_payment_df[column] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the other date columns to seconds and getting the differences between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date columns to seconds\n",
    "date_columns = ['booking_create_timestamp', 'booking_approved_at', 'booking_checkin_customer_date']\n",
    "\n",
    "for column in date_columns:\n",
    "    bookings_payment_df[column] = pd.to_datetime(bookings_payment_df[column])\n",
    "    # change to seconds\n",
    "    bookings_payment_df[column] = bookings_payment_df[column].astype(np.int64) // 10 ** 9\n",
    "\n",
    "# change approved-at to approved_at - create_timestamp\n",
    "bookings_payment_df['booking_approved_at'] = bookings_payment_df['booking_approved_at'] - bookings_payment_df['booking_create_timestamp']\n",
    "\n",
    "# change expiry to expiry - checkin\n",
    "bookings_payment_df['booking_expiry_date'] = bookings_payment_df['booking_expiry_date'] - bookings_payment_df['booking_checkin_customer_date']\n",
    "\n",
    "# create new column for expiry - create\n",
    "bookings_payment_df['booking_expiry_create'] = bookings_payment_df['booking_expiry_date'] - bookings_payment_df['booking_approved_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all columns\n",
    "columns = bookings_payment_df.columns\n",
    "\n",
    "# remove booking_id\n",
    "columns = columns.drop(['booking_id'])\n",
    "\n",
    "# change all null or nan values to mean of respective columns\n",
    "for column in columns:\n",
    "    mean = bookings_payment_df[column].mean()\n",
    "    bookings_payment_df[column].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale date columns using StandardScaler\n",
    "date_columns = ['booking_approved_at', 'booking_expiry_date']\n",
    "\n",
    "scaled_columns = StandardScaler().fit_transform(bookings_payment_df[date_columns])\n",
    "\n",
    "bookings_payment_df[date_columns] = scaled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert no null values\n",
    "assert bookings_payment_df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49868, 21)\n",
      "(49868,)\n"
     ]
    }
   ],
   "source": [
    "# train_booking_df contains bookings_df with booking_id in train_data\n",
    "train_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(train_data['booking_id'])]\n",
    "\n",
    "# create X_train and Y_train\n",
    "train_booking_df = train_booking_df.sort_values(by=['booking_id'])\n",
    "X_train = train_booking_df.drop(['booking_id'], axis=1)\n",
    "train_data = train_data.sort_values(by=['booking_id'])\n",
    "\n",
    "# take only unique values\n",
    "train_data = train_data.drop_duplicates(subset=['booking_id'])\n",
    "Y_train = train_data['rating_score']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "{'early_stopping': False, 'l2_regularization': 0.2, 'learning_rate': 0.05, 'loss': 'squared_error', 'max_depth': 5, 'max_iter': 400, 'max_leaf_nodes': 15, 'validation_fraction': 0.2}\n"
     ]
    }
   ],
   "source": [
    "params = {'early_stopping': False, 'l2_regularization': 0.2, 'learning_rate': 0.04, 'loss': 'squared_error', \n",
    "'max_depth': 4, 'max_iter': 500, 'max_leaf_nodes': 15, 'validation_fraction': 0.2}\n",
    "\n",
    "# grid_params around the above params for better results\n",
    "cv_params = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_leaf_nodes': [10, 15, 20],\n",
    "    'learning_rate': [0.03, 0.04, 0.05],\n",
    "    'l2_regularization': [0.1, 0.2, 0.3],\n",
    "    'max_iter': [400, 500, 600],\n",
    "    'validation_fraction': [0.2],\n",
    "    'early_stopping': [True, False],\n",
    "    'loss': ['squared_error']\n",
    "}\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(HistGradientBoostingRegressor(), cv_params, scoring='neg_mean_squared_error', cv=5, n_jobs=6, verbose=100)\n",
    "\n",
    "# fit grid search\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "# print best params\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3241385583434275\n",
      "1.2485873591595589\n"
     ]
    }
   ],
   "source": [
    "X_train_2, X_valid, Y_train_2, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = HistGradientBoostingRegressor(**params)\n",
    "rf.fit(X_train_2, Y_train_2)\n",
    "\n",
    "# mse of valid and train\n",
    "print(mean_squared_error(Y_valid, rf.predict(X_valid)))\n",
    "print(mean_squared_error(Y_train_2, rf.predict(X_train_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mse: 1.256188186359262\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.088837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.681466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.064135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.335550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.449554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.933109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating_score\n",
       "count  49079.000000\n",
       "mean       4.088837\n",
       "std        0.681466\n",
       "min        1.000000\n",
       "25%        4.064135\n",
       "50%        4.335550\n",
       "75%        4.449554\n",
       "max        4.933109"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use best parameters to train model\n",
    "# use best params\n",
    "model = HistGradientBoostingRegressor(**params)\n",
    "# fit model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "train_mse = mean_squared_error(Y_train, model.predict(X_train))\n",
    "print(\"train_mse: {}\".format(train_mse))\n",
    "\n",
    "test_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(test_data['booking_id'])]\n",
    "\n",
    "# create X_test\n",
    "test_booking_df = test_booking_df.sort_values(by=['booking_id'])\n",
    "X_test = test_booking_df.drop(['booking_id'], axis=1)\n",
    "\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# prepare submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['booking_id'] = test_booking_df['booking_id']\n",
    "submission['rating_score'] = Y_test_pred\n",
    "\n",
    "# change ratings below 0 to 0 and above 5 to 5\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 1 if x < 1 else x)\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 5 if x > 5 else x)\n",
    "\n",
    "submission.to_csv('main_submission-2.csv', index=False)\n",
    "submission.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f3a531bbf0f29f3151f5bd039b6fdd9153dda7bdef41c4c202a07430fcab450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
