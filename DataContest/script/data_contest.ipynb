{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "test_data = pd.read_csv('../data/sample_submission.csv')\n",
    "bookings_data = pd.read_csv('../data/bookings_data.csv')\n",
    "bookings = pd.read_csv('../data/bookings.csv')\n",
    "hotel_data = pd.read_csv('../data/hotels_data.csv')\n",
    "customer_data = pd.read_csv('../data/customer_data.csv')\n",
    "payments_data = pd.read_csv('../data/payments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only entries with payment_sequential as 1\n",
    "payments_data_unique = payments_data[payments_data['payment_sequential'] == 1]\n",
    "payments_data_repeat = payments_data[payments_data['payment_sequential'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making payment data unique for each booking_id\n",
    "for payment_data_repeat in payments_data_repeat.itertuples():\n",
    "    booking_id = payment_data_repeat.booking_id\n",
    "    payment_value_new = payments_data_unique[payments_data_unique['booking_id'] == booking_id]['payment_value'] + payment_data_repeat.payment_value\n",
    "    payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, 'payment_value'] = payment_value_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data count:  50000\n",
      "test_data count:  49079\n"
     ]
    }
   ],
   "source": [
    "# train_data count\n",
    "train_data_count = train_data.shape[0]\n",
    "print('train_data count: ', train_data_count)\n",
    "\n",
    "# test_data count\n",
    "test_data_count = test_data.shape[0]\n",
    "print('test_data count: ', test_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data_unique = bookings_data[bookings_data['booking_sequence_id'] == 1]\n",
    "bookings_data_repeat = bookings_data[bookings_data['booking_sequence_id'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging bookings_data for each booking_id\n",
    "for booking_data_repeat in bookings_data_repeat.itertuples():\n",
    "    bookings_id = booking_data_repeat.booking_id\n",
    "    booking_data_unique = bookings_data_unique[bookings_data_unique['booking_id'] == bookings_id]\n",
    "    new_price = booking_data_repeat.price + booking_data_unique.price\n",
    "    new_agent_fees = booking_data_repeat.agent_fees + booking_data_unique.agent_fees\n",
    "    bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, 'price'] = new_price\n",
    "    bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, 'agent_fees'] = new_agent_fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings and bookings_data as bookings_df\n",
    "bookings_df = pd.merge(bookings, bookings_data_unique, on='booking_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings_df and customer_data as bookings_customer_df\n",
    "bookings_customer_df = pd.merge(bookings_df, customer_data, on='customer_id', how='left')\n",
    "\n",
    "# merge bookings_customer_merged and hotel_data as bookings_hotel_merged\n",
    "bookings_hotel_df = pd.merge(bookings_customer_df, hotel_data, on='hotel_id', how='left')\n",
    "\n",
    "bookings_hotel_df.drop(['customer_id', 'hotel_id', 'booking_sequence_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booking_id                        object\n",
      "booking_status                      int8\n",
      "booking_create_timestamp          object\n",
      "booking_approved_at               object\n",
      "booking_checkin_customer_date     object\n",
      "seller_agent_id                    int16\n",
      "booking_expiry_date               object\n",
      "price                            float64\n",
      "agent_fees                       float64\n",
      "customer_unique_id                 int32\n",
      "country                             int8\n",
      "hotel_category                   float64\n",
      "hotel_name_length                float64\n",
      "hotel_description_length         float64\n",
      "hotel_photos_qty                 float64\n",
      "payment_type                        int8\n",
      "payment_installments             float64\n",
      "payment_value                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "bookings_payment_df = pd.merge(bookings_hotel_df, payments_data_unique, on='booking_id', how='left')\n",
    "\n",
    "bookings_payment_df.drop(['payment_sequential'], axis=1, inplace=True)\n",
    "\n",
    "cat_columns = ['seller_agent_id', 'booking_status', 'country', 'payment_type', 'customer_unique_id']\n",
    "\n",
    "for column in cat_columns:\n",
    "    bookings_payment_df[column] = bookings_payment_df[column].astype('category')\n",
    "    bookings_payment_df[column] = bookings_payment_df[column].cat.codes\n",
    "\n",
    "print(bookings_payment_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booking_id                        object\n",
      "booking_status                      int8\n",
      "booking_create_timestamp         float64\n",
      "booking_approved_at              float64\n",
      "booking_checkin_customer_date    float64\n",
      "seller_agent_id                    int16\n",
      "booking_expiry_date              float64\n",
      "price                            float64\n",
      "agent_fees                       float64\n",
      "customer_unique_id                 int32\n",
      "country                             int8\n",
      "hotel_category                   float64\n",
      "hotel_name_length                float64\n",
      "hotel_description_length         float64\n",
      "hotel_photos_qty                 float64\n",
      "payment_type                        int8\n",
      "payment_installments             float64\n",
      "payment_value                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "date_columns = ['booking_create_timestamp', 'booking_approved_at', 'booking_checkin_customer_date','booking_expiry_date']\n",
    "\n",
    "base_date = pd.to_datetime('2007-06-01')\n",
    "base_minutes = base_date.value / 10**9 / 60\n",
    "for date_column in date_columns:\n",
    "    bookings_payment_df[date_column] = pd.to_datetime(bookings_payment_df[date_column])\n",
    "    bookings_payment_df[date_column] = bookings_payment_df[date_column].apply(lambda x: (x.value / 10**9 / 60) - base_minutes)\n",
    "\n",
    "print(bookings_payment_df.dtypes)\n",
    "# bookings_payment_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49868, 17)\n",
      "(49868,)\n"
     ]
    }
   ],
   "source": [
    "# train_booking_df contains bookings_df with booking_id in train_data\n",
    "train_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(train_data['booking_id'])]\n",
    "\n",
    "# create X_train and Y_train\n",
    "train_booking_df = train_booking_df.sort_values(by=['booking_id'])\n",
    "X_train = train_booking_df.drop(['booking_id'], axis=1)\n",
    "train_data = train_data.sort_values(by=['booking_id'])\n",
    "# take only unique values\n",
    "train_data = train_data.drop_duplicates(subset=['booking_id'])\n",
    "Y_train = train_data['rating_score']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bersi\\AppData\\Local\\Temp\\ipykernel_23384\\2413715671.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  Y_train_actual = Y_train[: int(0.8 * len(Y_train))]\n",
      "C:\\Users\\bersi\\AppData\\Local\\Temp\\ipykernel_23384\\2413715671.py:4: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  Y_valid = Y_train[int(0.8 * len(Y_train)) :]\n"
     ]
    }
   ],
   "source": [
    "X_train_actual = X_train[: int(0.8 * len(X_train))]\n",
    "Y_train_actual = Y_train[: int(0.8 * len(Y_train))]\n",
    "X_valid = X_train[int(0.8 * len(X_train)) :]\n",
    "Y_valid = Y_train[int(0.8 * len(Y_train)) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3328133\ttest: 1.3324366\tbest: 1.3324366 (0)\ttotal: 71.5ms\tremaining: 1m 11s\n",
      "100:\tlearn: 1.1104983\ttest: 1.2242339\tbest: 1.2241424 (89)\ttotal: 6.52s\tremaining: 58.1s\n",
      "200:\tlearn: 1.0059021\ttest: 1.2187004\tbest: 1.2186467 (195)\ttotal: 12.8s\tremaining: 50.8s\n",
      "300:\tlearn: 0.9134255\ttest: 1.2187568\tbest: 1.2181422 (257)\ttotal: 19.1s\tremaining: 44.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.21814217\n",
      "bestIteration = 257\n",
      "\n",
      "Shrink model to first 258 iterations.\n",
      "[0]\tvalidation_0-rmse:3.56207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bersi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-rmse:1.20606\n",
      "[163]\tvalidation_0-rmse:1.20947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bersi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\bersi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.20131\n",
      "[200]\tvalid_0's rmse: 1.19789\n",
      "[300]\tvalid_0's rmse: 1.19803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.08, max_depth=12, metric=&#x27;rmse&#x27;,\n",
       "              n_estimators=1000, objective=&#x27;regression&#x27;, random_state=49)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.08, max_depth=12, metric=&#x27;rmse&#x27;,\n",
       "              n_estimators=1000, objective=&#x27;regression&#x27;, random_state=49)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(learning_rate=0.08, max_depth=12, metric='rmse',\n",
       "              n_estimators=1000, objective='regression', random_state=49)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor1 = CatBoostRegressor(iterations=1000, learning_rate=0.08, depth=12, loss_function='RMSE', eval_metric='RMSE', random_seed=49, od_type='Iter', od_wait=100)\n",
    "regressor2 = XGBRegressor(n_estimators=1000, learning_rate=0.08, max_depth=12, random_state=49, n_jobs=-1, objective='reg:squarederror', eval_metric='rmse')\n",
    "regressor3 = LGBMRegressor(n_estimators=1000, learning_rate=0.08, max_depth=12, random_state=49, n_jobs=-1, objective='regression', metric='rmse')\n",
    "\n",
    "regressor1.fit(X_train_actual, Y_train_actual, eval_set=(X_valid, Y_valid), use_best_model=True, verbose=100)\n",
    "regressor2.fit(X_train_actual, Y_train_actual, eval_set=[(X_valid, Y_valid)], early_stopping_rounds=100, verbose=100)\n",
    "regressor3.fit(X_train_actual, Y_train_actual, eval_set=[(X_valid, Y_valid)], early_stopping_rounds=100, verbose=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.037394\n",
      "RMSE: 1.430192\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred1 = regressor1.predict(X_train)\n",
    "Y_valid_pred1 = regressor1.predict(X_valid)\n",
    "\n",
    "Y_train_pred2 = regressor2.predict(X_train)\n",
    "Y_valid_pred2 = regressor2.predict(X_valid)\n",
    "\n",
    "Y_train_pred3 = regressor3.predict(X_train)\n",
    "Y_valid_pred3 = regressor3.predict(X_valid)\n",
    "\n",
    "Y_train_pred = (Y_train_pred1 + Y_train_pred2 + Y_train_pred3) / 3\n",
    "Y_valid_pred = (Y_valid_pred1 + Y_valid_pred2 + Y_valid_pred3) / 3\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(Y_train, Y_train_pred)\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "rmse_valid = mean_squared_error(Y_valid, Y_valid_pred)\n",
    "print(\"RMSE: %f\" % (rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.083279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.574748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.043376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.251229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.377894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.904847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating_score\n",
       "count  49079.000000\n",
       "mean       4.083279\n",
       "std        0.574748\n",
       "min        1.000000\n",
       "25%        4.043376\n",
       "50%        4.251229\n",
       "75%        4.377894\n",
       "max        4.904847"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(test_data['booking_id'])]\n",
    "\n",
    "# create X_test\n",
    "test_booking_df = test_booking_df.sort_values(by=['booking_id'])\n",
    "X_test = test_booking_df.drop(['booking_id'], axis=1)\n",
    "\n",
    "Y_test_pred = regressor1.predict(X_test)\n",
    "Y_test_pred2 = regressor2.predict(X_test)\n",
    "Y_test_pred3 = regressor3.predict(X_test)\n",
    "\n",
    "Y_test_pred = (Y_test_pred + Y_test_pred2 + Y_test_pred3) / 3\n",
    "\n",
    "# prepare submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['booking_id'] = test_booking_df['booking_id']\n",
    "submission['rating_score'] = Y_test_pred\n",
    "\n",
    "# change ratings below 0 to 0 and above 5 to 5\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 1 if x < 1 else x)\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 5 if x > 5 else x)\n",
    "\n",
    "submission.to_csv('submission_1.csv', index=False)\n",
    "submission.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f3a531bbf0f29f3151f5bd039b6fdd9153dda7bdef41c4c202a07430fcab450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
