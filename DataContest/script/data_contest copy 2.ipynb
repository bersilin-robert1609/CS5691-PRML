{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "test_data = pd.read_csv('../data/sample_submission.csv')\n",
    "bookings_data = pd.read_csv('../data/bookings_data.csv')\n",
    "bookings = pd.read_csv('../data/bookings.csv')\n",
    "hotel_data = pd.read_csv('../data/hotels_data.csv')\n",
    "customer_data = pd.read_csv('../data/customer_data.csv')\n",
    "payments_data = pd.read_csv('../data/payments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert payment type to numeric using sk preprocessing label encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(payments_data['payment_type'])\n",
    "payments_data['payment_type'] = le.transform(payments_data['payment_type'])\n",
    "\n",
    "# add 1 to the payment type to avoid 0 values\n",
    "payments_data['payment_type'] = payments_data['payment_type'] + 1\n",
    "\n",
    "payments_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only entries with payment_sequential as 1\n",
    "payments_data_unique = payments_data[payments_data['payment_sequential'] == 1]\n",
    "payments_data_repeat = payments_data[payments_data['payment_sequential'] > 1]\n",
    "\n",
    "payments_data_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort payments_data_repeat by payment_sequential\n",
    "payments_data_repeat = payments_data_repeat.sort_values(by=['payment_sequential'], ascending=True)\n",
    "\n",
    "payments_data_repeat.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making payment data unique for each booking_id by adding the payments made by other methods to primary payment method\n",
    "columns = ['payment_value', 'payment_installments', 'payment_type']\n",
    "\n",
    "for payment_data_repeat in payments_data_repeat.itertuples():\n",
    "    booking_id = payment_data_repeat.booking_id\n",
    "    payment_data_unique = payments_data_unique[payments_data_unique['booking_id'] == booking_id]\n",
    "    for column in columns:\n",
    "        new_value = payment_data_unique[column] + payment_data_repeat.__getattribute__(column)\n",
    "        payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, column] = new_value\n",
    "    payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, 'payment_sequential'] = payment_data_repeat.payment_sequential\n",
    "\n",
    "payments_data_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make columns values average based on payment_sequential\n",
    "for column in columns:\n",
    "    payments_data_unique[column] = payments_data_unique[column] / payments_data_unique['payment_sequential']\n",
    "\n",
    "payments_data_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data_new = bookings_data.merge(hotel_data, on='hotel_id', how='left')\n",
    "\n",
    "bookings_data_new.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split bookings_data into unique and repeat bookings\n",
    "bookings_data_unique = bookings_data_new[bookings_data_new['booking_sequence_id'] == 1]\n",
    "bookings_data_repeat = bookings_data_new[bookings_data_new['booking_sequence_id'] > 1]\n",
    "\n",
    "bookings_data_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort bookings_data_repeat by booking_sequence_id\n",
    "bookings_data_repeat = bookings_data_repeat.sort_values(by=['booking_sequence_id'], ascending=True)\n",
    "\n",
    "bookings_data_repeat.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging bookings_data for each booking_id\n",
    "columns = ['price', 'agent_fees', 'hotel_category', 'hotel_name_length', 'hotel_description_length', 'hotel_photos_qty', 'booking_expiry_date']\n",
    "\n",
    "for booking_data_repeat in bookings_data_repeat.itertuples():\n",
    "    bookings_id = booking_data_repeat.booking_id\n",
    "    booking_data_unique = bookings_data_unique[bookings_data_unique['booking_id'] == bookings_id]\n",
    "    for column in columns:\n",
    "        new_value = booking_data_unique[column] + booking_data_repeat.__getattribute__(column)\n",
    "        bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, column] = new_value\n",
    "    bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, 'booking_sequence_id'] = booking_data_repeat.booking_sequence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make entries in bookings_data_unique by taking average of the values based in booking_sequence_id\n",
    "columns = ['hotel_category', 'hotel_name_length', 'hotel_description_length', 'hotel_photos_qty', 'booking_expiry_date']\n",
    "\n",
    "for column in columns:\n",
    "    bookings_data_unique[column] = bookings_data_unique[column] / bookings_data_unique['booking_sequence_id']\n",
    "\n",
    "bookings_data_unique.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings and bookings_data as bookings_df\n",
    "bookings_df = pd.merge(bookings, bookings_data_unique, on='booking_id', how='left')\n",
    "\n",
    "bookings_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings_df and customer_data as bookings_customer_df\n",
    "bookings_customer_df = pd.merge(bookings_df, customer_data, on='customer_id', how='left')\n",
    "\n",
    "# merge bookings_hotel_df and payments_data as bookings_payment_df\n",
    "bookings_payment_df = pd.merge(bookings_customer_df, payments_data_unique, on='booking_id', how='left')\n",
    "\n",
    "bookings_payment_df.drop(['customer_id'], axis=1, inplace=True)\n",
    "\n",
    "bookings_payment_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['seller_agent_id', 'booking_status', 'country', 'customer_unique_id', 'hotel_id']\n",
    "\n",
    "for column in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(bookings_payment_df[column])\n",
    "    bookings_payment_df[column] = le.transform(bookings_payment_df[column])\n",
    "    if column == 'booking_status' or column == 'country':\n",
    "        bookings_payment_df[column] = bookings_payment_df[column] + 1\n",
    "\n",
    "print(bookings_payment_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['booking_create_timestamp', 'booking_approved_at', 'booking_checkin_customer_date', 'booking_expiry_date']\n",
    "\n",
    "for date_column in date_columns:\n",
    "    bookings_payment_df[date_column] = pd.to_datetime(bookings_payment_df[date_column])\n",
    "\n",
    "# change approved-at to approved_at - create_timestamp\n",
    "bookings_payment_df['booking_approved_at'] = bookings_payment_df['booking_approved_at'] - bookings_payment_df['booking_create_timestamp']\n",
    "bookings_payment_df['booking_approved_at'] = bookings_payment_df['booking_approved_at'].dt.total_seconds()\n",
    "\n",
    "# change expiry to expiry - checkin\n",
    "bookings_payment_df['booking_expiry_date'] = bookings_payment_df['booking_expiry_date'] - bookings_payment_df['booking_checkin_customer_date']\n",
    "bookings_payment_df['booking_expiry_date'] = bookings_payment_df['booking_expiry_date'].dt.total_seconds()\n",
    "\n",
    "print(bookings_payment_df.dtypes)\n",
    "bookings_payment_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_payment_df.drop(['booking_create_timestamp', 'booking_checkin_customer_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all columns\n",
    "columns = bookings_payment_df.columns\n",
    "\n",
    "# remove booking_id\n",
    "columns = columns.drop(['booking_id'])\n",
    "\n",
    "# change all null or nan values to mean of respective columns\n",
    "for column in columns:\n",
    "    mean = bookings_payment_df[column].mean()\n",
    "    bookings_payment_df[column].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bookings_payment_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_payment_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale date columns using StandardScaler\n",
    "date_columns = ['booking_approved_at', 'booking_expiry_date']\n",
    "\n",
    "scaled_columns = StandardScaler().fit_transform(bookings_payment_df[date_columns])\n",
    "\n",
    "bookings_payment_df[date_columns] = scaled_columns\n",
    "\n",
    "bookings_payment_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert no null values\n",
    "assert bookings_payment_df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_booking_df contains bookings_df with booking_id in train_data\n",
    "train_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(train_data['booking_id'])]\n",
    "\n",
    "# create X_train and Y_train\n",
    "train_booking_df = train_booking_df.sort_values(by=['booking_id'])\n",
    "X_train = train_booking_df.drop(['booking_id'], axis=1)\n",
    "train_data = train_data.sort_values(by=['booking_id'])\n",
    "\n",
    "# take only unique values\n",
    "train_data = train_data.drop_duplicates(subset=['booking_id'])\n",
    "Y_train = train_data['rating_score']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gridsearch cv to find best parameters for HistGradientBoostingRegressor\n",
    "param_grid = {\n",
    "    'learning_rate': [0.03, 0.04, 0.05, 0.06, 0.07, 0.1, 0.2],\n",
    "    'max_iter': [300, 400, 500, 600, 700],\n",
    "    'max_leaf_nodes': [15, 31, 63],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'l2_regularization': [0.1, 0.2, 0.3],\n",
    "    'early_stopping': [True, False],\n",
    "    'validation_fraction': [0.2],\n",
    "    'loss': ['squared_error']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=HistGradientBoostingRegressor(), param_grid=param_grid, cv=5, n_jobs=5, verbose=3)\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid.best_params_\n",
    "\n",
    "X_train_2, X_valid, Y_train_2, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# create ElasticNetCV model with best parameters\n",
    "elastic_net_cv = HistGradientBoostingRegressor(**params)\n",
    "\n",
    "# fit the model\n",
    "elastic_net_cv.fit(X_train_2, Y_train_2)\n",
    "\n",
    "train_mse = mean_squared_error(Y_train_2, elastic_net_cv.predict(X_train_2))\n",
    "val_mse = mean_squared_error(Y_valid, elastic_net_cv.predict(X_valid))\n",
    "\n",
    "print('Train MSE: ', train_mse)\n",
    "print('Validation MSE: ', val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best parameters to train model\n",
    "# use best params\n",
    "model = HistGradientBoostingRegressor(**params)\n",
    "# fit model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "train_mse = mean_squared_error(Y_train, model.predict(X_train))\n",
    "print(\"train_mse: {}\".format(train_mse))\n",
    "\n",
    "test_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(test_data['booking_id'])]\n",
    "\n",
    "# create X_test\n",
    "test_booking_df = test_booking_df.sort_values(by=['booking_id'])\n",
    "X_test = test_booking_df.drop(['booking_id'], axis=1)\n",
    "\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# prepare submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['booking_id'] = test_booking_df['booking_id']\n",
    "submission['rating_score'] = Y_test_pred\n",
    "\n",
    "# change ratings below 0 to 0 and above 5 to 5\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 1 if x < 1 else x)\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 5 if x > 5 else x)\n",
    "\n",
    "submission.to_csv('HistGrad-best-something-3.csv', index=False)\n",
    "submission.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f3a531bbf0f29f3151f5bd039b6fdd9153dda7bdef41c4c202a07430fcab450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
