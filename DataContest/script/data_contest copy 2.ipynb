{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "test_data = pd.read_csv('../data/sample_submission.csv')\n",
    "bookings_data = pd.read_csv('../data/bookings_data.csv')\n",
    "bookings = pd.read_csv('../data/bookings.csv')\n",
    "hotel_data = pd.read_csv('../data/hotels_data.csv')\n",
    "customer_data = pd.read_csv('../data/customer_data.csv')\n",
    "payments_data = pd.read_csv('../data/payments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert payment type to numeric using sk preprocessing label encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(payments_data['payment_type'])\n",
    "payments_data['payment_type'] = le.transform(payments_data['payment_type'])\n",
    "\n",
    "# add 1 to the payment type to avoid 0 values\n",
    "payments_data['payment_type'] = payments_data['payment_type'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only entries with payment_sequential as 1\n",
    "payments_data_unique = payments_data[payments_data['payment_sequential'] == 1]\n",
    "payments_data_repeat = payments_data[payments_data['payment_sequential'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort payments_data_repeat by payment_sequential\n",
    "payments_data_repeat = payments_data_repeat.sort_values(by=['payment_sequential'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making payment data unique for each booking_id by adding the payments made by other methods to primary payment method\n",
    "columns = ['payment_value', 'payment_installments', 'payment_type']\n",
    "\n",
    "for payment_data_repeat in payments_data_repeat.itertuples():\n",
    "    booking_id = payment_data_repeat.booking_id\n",
    "    payment_data_unique = payments_data_unique[payments_data_unique['booking_id'] == booking_id]\n",
    "    for column in columns:\n",
    "        new_value = payment_data_unique[column] + payment_data_repeat.__getattribute__(column)\n",
    "        payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, column] = new_value\n",
    "    payments_data_unique.loc[payments_data_unique['booking_id'] == booking_id, 'payment_sequential'] = payment_data_repeat.payment_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data_new = bookings_data.merge(hotel_data, on='hotel_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_data_new['booking_expiry_date'] = pd.to_datetime(bookings_data_new['booking_expiry_date'])\n",
    "# change to seconds\n",
    "bookings_data_new['booking_expiry_date'] = bookings_data_new['booking_expiry_date'].astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split bookings_data into unique and repeat bookings\n",
    "bookings_data_unique = bookings_data_new[bookings_data_new['booking_sequence_id'] == 1]\n",
    "bookings_data_repeat = bookings_data_new[bookings_data_new['booking_sequence_id'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort bookings_data_repeat by booking_sequence_id\n",
    "bookings_data_repeat = bookings_data_repeat.sort_values(by=['booking_sequence_id'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging bookings_data for each booking_id\n",
    "columns = ['price', 'agent_fees', 'hotel_category', 'hotel_name_length', 'hotel_description_length', 'hotel_photos_qty', 'booking_expiry_date']\n",
    "\n",
    "for booking_data_repeat in bookings_data_repeat.itertuples():\n",
    "    bookings_id = booking_data_repeat.booking_id\n",
    "    booking_data_unique = bookings_data_unique[bookings_data_unique['booking_id'] == bookings_id]\n",
    "    for column in columns:\n",
    "        new_value = booking_data_unique[column] + booking_data_repeat.__getattribute__(column)\n",
    "        bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, column] = new_value\n",
    "    bookings_data_unique.loc[bookings_data_unique['booking_id'] == bookings_id, 'booking_sequence_id'] = booking_data_repeat.booking_sequence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make entries in bookings_data_unique by taking average of the values based in booking_sequence_id\n",
    "columns = ['hotel_category', 'hotel_name_length', 'hotel_description_length', 'hotel_photos_qty', 'booking_expiry_date']\n",
    "\n",
    "for column in columns:\n",
    "    bookings_data_unique[column] = bookings_data_unique[column] / bookings_data_unique['booking_sequence_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings and bookings_data as bookings_df\n",
    "bookings_df = pd.merge(bookings, bookings_data_unique, on='booking_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bookings_df and customer_data as bookings_customer_df\n",
    "bookings_customer_df = pd.merge(bookings_df, customer_data, on='customer_id', how='left')\n",
    "\n",
    "# merge bookings_hotel_df and payments_data as bookings_payment_df\n",
    "bookings_payment_df = pd.merge(bookings_customer_df, payments_data_unique, on='booking_id', how='left')\n",
    "\n",
    "bookings_payment_df.drop(['customer_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['seller_agent_id', 'booking_status', 'country', 'customer_unique_id', 'hotel_id']\n",
    "\n",
    "for column in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(bookings_payment_df[column])\n",
    "    bookings_payment_df[column] = le.transform(bookings_payment_df[column])\n",
    "    if column == 'booking_status' or column == 'country':\n",
    "        bookings_payment_df[column] = bookings_payment_df[column] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date columns to seconds \n",
    "# booking_create_timestamp\n",
    "# booking_approved_at \n",
    "# booking_checkin_customer_date\n",
    "date_columns = ['booking_create_timestamp', 'booking_approved_at', 'booking_checkin_customer_date']\n",
    "\n",
    "for column in date_columns:\n",
    "    bookings_payment_df[column] = pd.to_datetime(bookings_payment_df[column])\n",
    "    # change to seconds\n",
    "    bookings_payment_df[column] = bookings_payment_df[column].astype(np.int64) // 10 ** 9\n",
    "\n",
    "# change approved-at to approved_at - create_timestamp\n",
    "bookings_payment_df['booking_approved_at'] = bookings_payment_df['booking_approved_at'] - bookings_payment_df['booking_create_timestamp']\n",
    "\n",
    "# change expiry to expiry - checkin\n",
    "bookings_payment_df['booking_expiry_date'] = bookings_payment_df['booking_expiry_date'] - bookings_payment_df['booking_checkin_customer_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_payment_df.drop(['booking_create_timestamp', 'booking_checkin_customer_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all columns\n",
    "columns = bookings_payment_df.columns\n",
    "\n",
    "# remove booking_id\n",
    "columns = columns.drop(['booking_id'])\n",
    "\n",
    "# change all null or nan values to mean of respective columns\n",
    "for column in columns:\n",
    "    mean = bookings_payment_df[column].mean()\n",
    "    bookings_payment_df[column].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booking_id                   object\n",
      "booking_status                int32\n",
      "booking_approved_at           int64\n",
      "booking_sequence_id         float64\n",
      "hotel_id                      int32\n",
      "seller_agent_id               int32\n",
      "booking_expiry_date         float64\n",
      "price                       float64\n",
      "agent_fees                  float64\n",
      "hotel_category              float64\n",
      "hotel_name_length           float64\n",
      "hotel_description_length    float64\n",
      "hotel_photos_qty            float64\n",
      "customer_unique_id            int32\n",
      "country                       int32\n",
      "payment_sequential          float64\n",
      "payment_type                float64\n",
      "payment_installments        float64\n",
      "payment_value               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(bookings_payment_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booking_id</th>\n",
       "      <th>booking_status</th>\n",
       "      <th>booking_approved_at</th>\n",
       "      <th>booking_sequence_id</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>seller_agent_id</th>\n",
       "      <th>booking_expiry_date</th>\n",
       "      <th>price</th>\n",
       "      <th>agent_fees</th>\n",
       "      <th>hotel_category</th>\n",
       "      <th>hotel_name_length</th>\n",
       "      <th>hotel_description_length</th>\n",
       "      <th>hotel_photos_qty</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>country</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99441</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>9.944100e+04</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>9.944100e+04</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "      <td>99441.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>99441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>c54678b7cc49136f2d6af7e481f51cbd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.076166</td>\n",
       "      <td>-4.001407e-18</td>\n",
       "      <td>1.141731</td>\n",
       "      <td>16030.302461</td>\n",
       "      <td>1417.288995</td>\n",
       "      <td>6.148591e-17</td>\n",
       "      <td>137.754076</td>\n",
       "      <td>22.823562</td>\n",
       "      <td>28.857976</td>\n",
       "      <td>48.843101</td>\n",
       "      <td>794.016654</td>\n",
       "      <td>2.249931</td>\n",
       "      <td>48049.895224</td>\n",
       "      <td>5.011484</td>\n",
       "      <td>1.044726</td>\n",
       "      <td>1.690378</td>\n",
       "      <td>2.981310</td>\n",
       "      <td>160.984584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561226</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>0.536350</td>\n",
       "      <td>9287.168077</td>\n",
       "      <td>935.610297</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>209.822693</td>\n",
       "      <td>21.566375</td>\n",
       "      <td>22.373529</td>\n",
       "      <td>9.846012</td>\n",
       "      <td>645.565179</td>\n",
       "      <td>1.720124</td>\n",
       "      <td>27758.278975</td>\n",
       "      <td>2.580036</td>\n",
       "      <td>0.381138</td>\n",
       "      <td>2.148253</td>\n",
       "      <td>2.740687</td>\n",
       "      <td>221.907616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.496703e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.625356e-01</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.005658e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7995.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>-1.513949e-01</td>\n",
       "      <td>45.990000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23986.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.005768e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16249.000000</td>\n",
       "      <td>1342.000000</td>\n",
       "      <td>-1.511389e-01</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>17.270000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48053.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>105.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.017999e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23920.000000</td>\n",
       "      <td>2260.000000</td>\n",
       "      <td>-1.509277e-01</td>\n",
       "      <td>149.900000</td>\n",
       "      <td>23.920000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>72088.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>176.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.890892e-02</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>31881.000000</td>\n",
       "      <td>3088.000000</td>\n",
       "      <td>6.708564e+00</td>\n",
       "      <td>13440.000000</td>\n",
       "      <td>1794.960000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>3992.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>96095.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13664.080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              booking_id  booking_status  booking_approved_at  \\\n",
       "count                              99441    99441.000000         9.944100e+04   \n",
       "unique                             99441             NaN                  NaN   \n",
       "top     c54678b7cc49136f2d6af7e481f51cbd             NaN                  NaN   \n",
       "freq                                   1             NaN                  NaN   \n",
       "mean                                 NaN        3.076166        -4.001407e-18   \n",
       "std                                  NaN        0.561226         1.000005e+00   \n",
       "min                                  NaN        1.000000        -2.496703e+01   \n",
       "25%                                  NaN        3.000000         4.005658e-02   \n",
       "50%                                  NaN        3.000000         4.005768e-02   \n",
       "75%                                  NaN        3.000000         4.017999e-02   \n",
       "max                                  NaN        8.000000         7.890892e-02   \n",
       "\n",
       "        booking_sequence_id      hotel_id  seller_agent_id  \\\n",
       "count          99441.000000  99441.000000     99441.000000   \n",
       "unique                  NaN           NaN              NaN   \n",
       "top                     NaN           NaN              NaN   \n",
       "freq                    NaN           NaN              NaN   \n",
       "mean               1.141731  16030.302461      1417.288995   \n",
       "std                0.536350   9287.168077       935.610297   \n",
       "min                1.000000      0.000000         0.000000   \n",
       "25%                1.000000   7995.000000       526.000000   \n",
       "50%                1.000000  16249.000000      1342.000000   \n",
       "75%                1.000000  23920.000000      2260.000000   \n",
       "max               21.000000  31881.000000      3088.000000   \n",
       "\n",
       "        booking_expiry_date         price    agent_fees  hotel_category  \\\n",
       "count          9.944100e+04  99441.000000  99441.000000    99441.000000   \n",
       "unique                  NaN           NaN           NaN             NaN   \n",
       "top                     NaN           NaN           NaN             NaN   \n",
       "freq                    NaN           NaN           NaN             NaN   \n",
       "mean           6.148591e-17    137.754076     22.823562       28.857976   \n",
       "std            1.000005e+00    209.822693     21.566375       22.373529   \n",
       "min           -1.625356e-01      0.850000      0.000000        1.000000   \n",
       "25%           -1.513949e-01     45.990000     13.900000       10.000000   \n",
       "50%           -1.511389e-01     88.000000     17.270000       28.000000   \n",
       "75%           -1.509277e-01    149.900000     23.920000       38.000000   \n",
       "max            6.708564e+00  13440.000000   1794.960000       73.000000   \n",
       "\n",
       "        hotel_name_length  hotel_description_length  hotel_photos_qty  \\\n",
       "count        99441.000000              99441.000000      99441.000000   \n",
       "unique                NaN                       NaN               NaN   \n",
       "top                   NaN                       NaN               NaN   \n",
       "freq                  NaN                       NaN               NaN   \n",
       "mean            48.843101                794.016654          2.249931   \n",
       "std              9.846012                645.565179          1.720124   \n",
       "min              5.000000                  4.000000          1.000000   \n",
       "25%             43.000000                357.000000          1.000000   \n",
       "50%             51.000000                621.000000          2.000000   \n",
       "75%             57.000000                982.000000          3.000000   \n",
       "max             76.000000               3992.000000         20.000000   \n",
       "\n",
       "        customer_unique_id       country  payment_sequential  payment_type  \\\n",
       "count         99441.000000  99441.000000        99441.000000  99441.000000   \n",
       "unique                 NaN           NaN                 NaN           NaN   \n",
       "top                    NaN           NaN                 NaN           NaN   \n",
       "freq                   NaN           NaN                 NaN           NaN   \n",
       "mean          48049.895224      5.011484            1.044726      1.690378   \n",
       "std           27758.278975      2.580036            0.381138      2.148253   \n",
       "min               0.000000      1.000000            1.000000      1.000000   \n",
       "25%           23986.000000      3.000000            1.000000      1.000000   \n",
       "50%           48053.000000      5.000000            1.000000      1.000000   \n",
       "75%           72088.000000      7.000000            1.000000      2.000000   \n",
       "max           96095.000000      9.000000           29.000000    145.000000   \n",
       "\n",
       "        payment_installments  payment_value  \n",
       "count           99441.000000   99441.000000  \n",
       "unique                   NaN            NaN  \n",
       "top                      NaN            NaN  \n",
       "freq                     NaN            NaN  \n",
       "mean                2.981310     160.984584  \n",
       "std                 2.740687     221.907616  \n",
       "min                 1.000000       0.000000  \n",
       "25%                 1.000000      62.010000  \n",
       "50%                 2.000000     105.370000  \n",
       "75%                 4.000000     176.860000  \n",
       "max                29.000000   13664.080000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale date columns using StandardScaler\n",
    "date_columns = ['booking_approved_at', 'booking_expiry_date']\n",
    "\n",
    "scaled_columns = StandardScaler().fit_transform(bookings_payment_df[date_columns])\n",
    "\n",
    "bookings_payment_df[date_columns] = scaled_columns\n",
    "\n",
    "bookings_payment_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert no null values\n",
    "assert bookings_payment_df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49868, 18)\n",
      "(49868,)\n"
     ]
    }
   ],
   "source": [
    "# train_booking_df contains bookings_df with booking_id in train_data\n",
    "train_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(train_data['booking_id'])]\n",
    "\n",
    "# create X_train and Y_train\n",
    "train_booking_df = train_booking_df.sort_values(by=['booking_id'])\n",
    "X_train = train_booking_df.drop(['booking_id'], axis=1)\n",
    "train_data = train_data.sort_values(by=['booking_id'])\n",
    "\n",
    "# take only unique values\n",
    "train_data = train_data.drop_duplicates(subset=['booking_id'])\n",
    "Y_train = train_data['rating_score']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4000 candidates, totalling 20000 fits\n"
     ]
    }
   ],
   "source": [
    "# # data processing \n",
    "# 'learning_rate': [0.05],\n",
    "#     'max_iter': [500],\n",
    "#     'max_leaf_nodes': [31],\n",
    "#     'max_depth': [7],\n",
    "#     'l2_regularization': [0.2],\n",
    "#     'early_stopping': [False],\n",
    "#     'validation_fraction': [0.2],\n",
    "#     'loss': ['squared_error']\n",
    "# histgradboosting\n",
    "\n",
    "# use gridsearch cv to find best parameters for HistGradientBoostingRegressor\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.1],\n",
    "    'max_iter': [500, 600, 700, 800],\n",
    "    'max_leaf_nodes': [10, 12, 15, 31, None],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'l2_regularization': [ 0.15, 0.2, 0.25, 0.3],\n",
    "    'early_stopping': [True, False],\n",
    "    'validation_fraction': [0.2],\n",
    "    'loss': ['squared_error']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=HistGradientBoostingRegressor(), param_grid=param_grid, cv=5, n_jobs=6, verbose=3)\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE:  1.2562290011297357\n",
      "Validation MSE:  1.3318898764664076\n"
     ]
    }
   ],
   "source": [
    "params = grid.best_params_\n",
    "\n",
    "X_train_2, X_valid, Y_train_2, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# create ElasticNetCV model with best parameters\n",
    "elastic_net_cv = HistGradientBoostingRegressor(**params)\n",
    "\n",
    "# fit the model\n",
    "elastic_net_cv.fit(X_train_2, Y_train_2)\n",
    "\n",
    "train_mse = mean_squared_error(Y_train_2, elastic_net_cv.predict(X_train_2))\n",
    "val_mse = mean_squared_error(Y_valid, elastic_net_cv.predict(X_valid))\n",
    "\n",
    "print('Train MSE: ', train_mse)\n",
    "print('Validation MSE: ', val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mse: 1.2664811461469232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.089499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.673513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.077994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.342336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.446725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.986167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating_score\n",
       "count  49079.000000\n",
       "mean       4.089499\n",
       "std        0.673513\n",
       "min        1.000000\n",
       "25%        4.077994\n",
       "50%        4.342336\n",
       "75%        4.446725\n",
       "max        4.986167"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use best parameters to train model\n",
    "# use best params\n",
    "model = HistGradientBoostingRegressor(**params)\n",
    "# fit model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "train_mse = mean_squared_error(Y_train, model.predict(X_train))\n",
    "print(\"train_mse: {}\".format(train_mse))\n",
    "\n",
    "test_booking_df = bookings_payment_df[bookings_payment_df['booking_id'].isin(test_data['booking_id'])]\n",
    "\n",
    "# create X_test\n",
    "test_booking_df = test_booking_df.sort_values(by=['booking_id'])\n",
    "X_test = test_booking_df.drop(['booking_id'], axis=1)\n",
    "\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# prepare submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['booking_id'] = test_booking_df['booking_id']\n",
    "submission['rating_score'] = Y_test_pred\n",
    "\n",
    "# change ratings below 0 to 0 and above 5 to 5\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 1 if x < 1 else x)\n",
    "submission['rating_score'] = submission['rating_score'].apply(lambda x: 5 if x > 5 else x)\n",
    "\n",
    "submission.to_csv('HistGrad-best-something-5.csv', index=False)\n",
    "submission.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f3a531bbf0f29f3151f5bd039b6fdd9153dda7bdef41c4c202a07430fcab450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
